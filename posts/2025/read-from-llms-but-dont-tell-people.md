---
title: Read from LLMs but don't tell people
date: "2025-03-07T05:08:18Z"
lastmod: "2025-03-07T05:08:20Z"
categories:
  - llms
wp_id: 3951
---

![Read from LLMs but don't tell people](/blog/assets/calvin-meeting.webp)

In meetings, I pass on questions to ChatGPT and I read out the response. But I've stopped saying "I'm reading that from ChatGPT."

(By "ChatGPT", I mean ChatGPT, Claude, Grok, Gemini, Meta, etc. I happen to use ChatGPT with O3 Mini + Search.)

### Use ChatGPT in meetings

It's good to bring ChatGPT into conversations. (Or any activity where intelligence helps, actually.)

In meetings (online or in person), I keep a ChatGPT window open. When asked:

1. "What'll you have, Anand?" (at restaurants)
2. "How can doctors use LLMs?"
3. "Will you review this technical architecture?"

If I know the answer, I'll give it. If not, I ask ChatGPT. (Ideally, I should ask **even** if I **think** I know the answer.)

For example:

1. Sharing the menu photo and ask, "List vegetarian options. Suggest innovative dishes I'll like." (This works because I've shared my preferences and history with ChatGPT.)
2. "How can doctors use LLMs in day-to-day work?"
3. Sharing a picture of the architecture, "Explain this architecture to a blind expert. Critique with strengths, critical issues, and optional improvements."

I've learnt that:

1. **Note-taking helps**. I touch-type (without looking). I copy-paste the notes **and** their question to the LLM.
2. **Short questions are fine**. Newer models understand cryptic questions.
3. **Say "Give me 30 seconds"**. People assume **you're** thinking deeply.

### Read the response your way

I just read out the response -- but with some changes.

1. **Change style**. I read quicky, internalize, and say it in my style. Instead of "1. Clinical Documentation & Administrative Support", I'd say, "Doctors can use it for note-taking."
2. **Filter content**. I skip stuff I don't get or like. I might miss stuff, but when I speak, it's **my** opinion I represent.
3. **Add context**. I add personal stories to make it real, if I can. "GPs I know are worried LLMs diagnose better than they do" is something LLMs may not have learnt yet.

### Don't say you're reading from ChatGPT

I used to tell people, "â€¦ and I just read that out from ChatGPT." Their response is always:

1. **Disbelief** for a moment.
2. **Amazement** that models are so good.
3. **Dismissal** of what I said, since it's not "real". (This is the sad part.)

I stopped saying that because

- **I don't need to**. I can promote LLMs elsewhere.
- **It's not true**. I re-style, filter, add context. It's **my** response. **My** responsibility.

I'd rather deliver useful ideas than show where they come from. And if they think I'm a genius? Fine by me ðŸ™‚
