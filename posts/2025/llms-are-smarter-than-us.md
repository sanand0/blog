---
date: "2025-07-01T06:46:10Z"
categories:
  - linkedin
---

LLMs are smarter than us in many areas. How do we control them?

It's not a new problem.

- **VC partners** evaluate deep-tech startups.
- **Science editors** review Nobel laureates.
- **Managers** manage specialist teams.
- **Judges** evaluate expert testimony.
- **Coaches** train Olympic athletes.

â€¦ and they manage and evaluate "smarter" outputs in _many_ ways:

- **Verify**. Check against an "answer sheet".
- **Checklist**. Evaluate against pre-defined criteria.
- **Sampling**. Randomly review a subset.
- **Gating**. Accept low-risk work. Evaluate critical ones.
- **Benchmark**. Compare against others.
- **Red-team**. Probe to expose hidden flaws.
- **Double-blind review**. Mask identity to curb bias.
- **Reproduce**. Re-running gives the same output?
- **Consensus**. Ask many. Wisdom of crowds.
- **Outcome**. Did it work in the real world?

For example, you can apply them to:

- **Vibe coding**: Non-programmers might glance at lint checks (_Checklist_) and see if it works (_Outcome_).
- **LLM image designs**: Developers might check if a few images look good (_Sampling_) and check a few marketers (_Consensus_).
- **LLM news articles**: An journalist might run a _Checklist_, a _Double-blind review_ with experts, and _Verify_ critical facts (_Gating_).

You _already_ know many of these. You learnt them in Auditing. Statistics. Law. System controls. Policy analysis. Quality engineering. Clinical epidemiology. Investigative journalism. Design critique.

Worth brushing up on these skills. They're _more_ important in the AI era.

ChatGPT: https://chatgpt.com/share/6863733f-4ebc-800c-ad3f-a2b472d9e9ca

![](https://files.s-anand.net/images/2025-07-01-llms-are-smarter-than-us-linkedin.jpg)

[LinkedIn](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7345704252889059331)
